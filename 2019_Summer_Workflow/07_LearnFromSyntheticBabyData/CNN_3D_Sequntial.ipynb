{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import from the Keras library\n",
    "from keras import models\n",
    "from keras.layers import Dense, Dropout, Flatten, Input \n",
    "from keras.layers import Conv2D,  MaxPooling2D, TimeDistributed, LSTM, Conv3D, MaxPooling3D\n",
    "from keras.models import Model\n",
    "from keras import optimizers \n",
    "from keras import utils\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "#from secret import credentials\n",
    "\n",
    "#This allows for Keras models to be saved. \n",
    "import h5py\n",
    "#Other import statements \n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import cv2\n",
    "import pymysql\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect(): \n",
    "    db_host ='nicu-2019-03-05.c2lckhwrw1as.us-east-1.rds.amazonaws.com'\n",
    "    db_port = 3306\n",
    "    db_name = 'nicu'\n",
    "    db_username = 'jonlee'\n",
    "    db_password = 'nicu_jon'\n",
    "    \n",
    "    '''\n",
    "    db_host = credentials['db_host'];\n",
    "    db_port = credentials['db_port'];\n",
    "    db_name = credentials['db_name'];\n",
    "    db_username = credentials['db_username']\n",
    "    db_password = credentials['db_password']\n",
    "    '''\n",
    "    \n",
    "    conn = pymysql.connect(db_host, user=db_username, port=db_port, passwd=db_password, db=db_name)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_data(cache_path, conn=connect()): \n",
    "\n",
    "    curs = conn.cursor()\n",
    "    \n",
    "    recording_ids = {}\n",
    "    xy = {}    \n",
    "        \n",
    "    image_query = \"SELECT r.id, r.recording_id, r.isCSGM FROM nicu.Video_Raw AS r JOIN nicu.Video_Generated AS g ON r.id=g.raw_id  WHERE (r.recording_id>1) AND (g.RGB_Optical_Flow IS NOT NULL) LIMIT 5000\"\n",
    "    try:\n",
    "        curs.execute(image_query) #(list(recording_ids.keys())))\n",
    "        for row in curs.fetchall():\n",
    "            raw_id = row[0]\n",
    "            rec_id = row[1]\n",
    "            csgm = row[2]\n",
    "            if rec_id in recording_ids:\n",
    "                recording_ids.get(rec_id).append(raw_id)\n",
    "            else:\n",
    "                recording_ids.update({rec_id:[raw_id]})\n",
    "            xy.update({raw_id:[csgm]})\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving ID's\", e)\n",
    "        raise e\n",
    "    \n",
    "    cache_path = cache_path+'testing'   \n",
    "    for rec_id in recording_ids:\n",
    "        #cache_path = cache_path+\"recording_\"+(\"{:02d}\".format(rec_id))\n",
    "        if not os.path.exists(cache_path):\n",
    "            os.mkdir(cache_path)\n",
    "            \n",
    "        #Temporarily shortens the amount of data to use to be able to test\n",
    "        raw_id_list = recording_ids.get(rec_id)[:200]\n",
    "        recording_ids.update({rec_id:raw_id_list})\n",
    "        for raw_id in raw_id_list:\n",
    "            rgb_path = cache_path+'/'+str(raw_id)+\".oflow.png\"\n",
    "            depth_path = cache_path+'/'+str(raw_id)+\".dflow.png\"\n",
    "            if not (os.path.exists(rgb_path) and os.path.exists(depth_path)):\n",
    "                try:\n",
    "                    image_query = \"SELECT RGB_Optical_Flow, D_Depth_Flow from Video_Generated WHERE (raw_id=%s)\"\n",
    "                    curs.execute(image_query, (str(raw_id)))\n",
    "                    for row in curs.fetchall():\n",
    "                        rgb_img = row[0]\n",
    "                        depth_img = row[1]\n",
    "                        if (rgb_img is not None) and not(os.path.exists(rgb_path)):\n",
    "                            rgb_cv = cv2.imdecode(np.asarray(bytearray(rgb_img),dtype=np.uint8),cv2.IMREAD_UNCHANGED)\n",
    "                            cv2.imwrite(rgb_path,rgb_cv)\n",
    "                        if depth_img is not None and not(os.path.exists(depth_path)):\n",
    "                            depth_cv = cv2.imdecode(np.asarray(bytearray(depth_img),dtype=np.uint8),cv2.IMREAD_UNCHANGED)\n",
    "                            cv2.imwrite(depth_path,depth_cv)\n",
    "                except Exception as e:\n",
    "                        print(\"Error retrieving Optical Flow frame\",e)\n",
    "                        curs.close();\n",
    "                        raise e\n",
    "            #Resizing the image to a quarter of the size\n",
    "            scale = 20\n",
    "            if os.path.exists(rgb_path) and os.path.exists(depth_path):\n",
    "                rgb_img = resize(rgb_path,scale)\n",
    "                depth_img = resize(depth_path,scale)\n",
    "                xy.get(raw_id).extend([rgb_img,depth_img])\n",
    "            else: \n",
    "                xy.pop(raw_id)\n",
    "                recording_ids.get(rec_id).remove(raw_id)\n",
    "    curs.close()\n",
    "    \n",
    "    return recording_ids, xy\n",
    "\n",
    "def resize(path, scale):\n",
    "    '''\n",
    "    Creates and resizes a cv2 image to scale/100\n",
    "    '''\n",
    "    img = cv2.imread(path)\n",
    "    width = int(img.shape[1] * (scale / 100))\n",
    "    height = int(img.shape[0] * (scale / 100))\n",
    "    img = cv2.resize(img,(width,height), interpolation=cv2.INTER_CUBIC)\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_array(id_dict, xy):    \n",
    "    rgb_list=[]\n",
    "    depth_list=[]\n",
    "    csgm_list=[]\n",
    "    \n",
    "    for i in id_dict:\n",
    "        frames = id_dict.get(i)\n",
    "        for j in range(len(frames)): \n",
    "            if j>10:\n",
    "                seq_frames = frames[(j-10):j]\n",
    "                seq_rgb = []\n",
    "                seq_depth = []\n",
    "                append = True\n",
    "                for f in seq_frames:\n",
    "                    if len(xy.get(f)) == 3:\n",
    "                        seq_rgb.append(list(xy.get(f)[1]))\n",
    "                        seq_depth.append(list(xy.get(f)[2]))\n",
    "                    else: \n",
    "                        append = False\n",
    "                \n",
    "                sum_squared = sum([xy.get(f)[0] for f in seq_frames])\n",
    "                csgm = 1 if (sum_squared/10) > 0.5 else 0\n",
    "                \n",
    "                if append: \n",
    "                    rgb_list.append(seq_rgb)\n",
    "                    depth_list.append(seq_depth)\n",
    "                    csgm_list.append(csgm)\n",
    "                    \n",
    "    num_is = 0\n",
    "    num_isnt = 0\n",
    "    for j in csgm_list:\n",
    "        if j == 0: \n",
    "            num_isnt += 1\n",
    "        else:\n",
    "            num_is += 1\n",
    "    \n",
    "    counter = 0\n",
    "    added = 0\n",
    "    length = len(rgb_list)\n",
    "    \n",
    "    while added < ((num_isnt-num_is)/2):\n",
    "        if csgm_list[counter % length] == 1:\n",
    "            rgb_list.append(rgb_list[(counter % length)])\n",
    "            depth_list.append(depth_list[(counter % length)])\n",
    "            csgm_list.append(csgm_list[(counter % length)])\n",
    "            added += 1\n",
    "        counter += 1\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "    print('Num is %d and num isn\\'t %d' %(num_is, num_isnt))\n",
    "              \n",
    "    print('Length of training set\\n' + str(len(rgb_list)))\n",
    "    x_rgb = np.array(rgb_list)\n",
    "    x_depth = np.array(depth_list)\n",
    "    y = np.array(csgm_list)\n",
    "    return x_rgb, x_depth, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cnn(x_train, filter_info={0:[32,3]}, dropout={0:0.25}, pooling={0:2}, activation='relu', loss='mean_squared_error', final_activation='sigmoid'):    \n",
    "    \n",
    "    model = models.Sequential() \n",
    "    str_model = \"Overview of Model Architecture: \\n\"\n",
    "    \n",
    "    filter_size = 0\n",
    "    \n",
    "    for i in filter_info: \n",
    "        filter_size = filter_info.get(i)[1]\n",
    "        num_filters = filter_info.get(i)[0]\n",
    "        \n",
    "        if i == 0: \n",
    "            model.add(Conv2D(num_filters, (filter_size,filter_size), activation = 'relu', input_shape=x_train.shape[1:][1:]))\n",
    "        else: \n",
    "            model.add(Conv2D(num_filters, (filter_size,filter_size), activation= 'relu'))\n",
    "        \n",
    "        str_model += (\"2D Convulution Layer with %d filters the size of (%d,%d) and %s activation \\n\" %(num_filters, filter_size, filter_size, activation))\n",
    "        \n",
    "        model.add(Conv2D(num_filters, (filter_size,filter_size), activation= 'relu'))\n",
    "        str_model += (\"2D Convulution Layer with %d filters the size of (%d,%d) and %s activation \\n\" %(num_filters, filter_size, filter_size, activation))\n",
    "        \n",
    "        if i in pooling:           \n",
    "            pool_filter_size = pooling.get(i)\n",
    "            model.add(MaxPooling2D(pool_size=(pool_filter_size, pool_filter_size)))\n",
    "            str_model += ('2D Pooling Max Pooling Layer with filter size (%d,%d)\\n' %(pool_filter_size,pool_filter_size))\n",
    "            \n",
    "                 \n",
    "        if i in dropout: \n",
    "            drop_rate = dropout.get(i)\n",
    "            model.add(Dropout(drop_rate))\n",
    "            str_model += ('Droput Layer with with a rate of %f \\n' %(drop_rate))\n",
    "\n",
    "\n",
    "    \n",
    "    #These will be added to the end of every model no matter what\n",
    "#     model.add(Flatten())\n",
    "#     str_model += ('Flatten\\n')\n",
    "\n",
    "                      \n",
    "    print(str_model)\n",
    "\n",
    "    return model, str_model\n",
    "\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(exp_values, predicted_values):\n",
    "    \"\"\"\n",
    "    This creates a confusion matrix with the predicted accuracy of the model.\n",
    "    \n",
    "    exp_values must be in the format of a list and predicted values is expected to come in the format of the ouput \n",
    "    of Keras's model.predict()\n",
    "    \n",
    "    The ouput is a pandas dataframe that displays a confusion matrix indicitive of the accuracy of the model along \n",
    "        with a number score which is the accuracy of the model.\n",
    "    \"\"\"\n",
    "    predicted_values = convert_predictions(predicted_values)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Creates a DataFrame of zeros\n",
    "    matrix = pd.DataFrame(np.zeros((2,2)) , ['P0','P1'], ['E0','E1'])\n",
    "   \n",
    "    #Caculates whether the score was right or wrong and updates the confusion matrix \n",
    "    for i in range(len(exp_values)):\n",
    "        if exp_values[i] == predicted_values[i]:\n",
    "            matrix.iloc[[predicted_values[i]],[predicted_values[i]]] += 1\n",
    "        else:\n",
    "            matrix.iloc[[predicted_values[i]],[exp_values[i]]] += 1\n",
    "   \n",
    "    #Calculate diagonal sum and the accuracy of the model\n",
    "    #Precision (TP/TP+FPos)      Recall TP(TP+FNegative)\n",
    "    diagonal_sum = 0\n",
    "    for i in range(2):\n",
    "        diagonal_sum += matrix.iloc[i][i]\n",
    "    \n",
    "    score = diagonal_sum/len(exp_values)\n",
    "    \n",
    "  \n",
    "    return  matrix, score\n",
    "    \n",
    "    \n",
    "            \n",
    "def convert_predictions(predictions): \n",
    "    \"\"\"\n",
    "    Converts predictions outputted by a keras model into a list with 1 represented the predicted output and zero \n",
    "    in other classes. \n",
    "    \"\"\"\n",
    "    l =[]\n",
    "    max_prediction = 0\n",
    "    \n",
    "    for p in predictions:\n",
    "        if p > max_prediction:\n",
    "            max_prediction = p\n",
    "    \n",
    "    for p in predictions: \n",
    "        p = p/max_prediction\n",
    "        if p >= 0.5:\n",
    "            l.append(1)\n",
    "        else:\n",
    "            l.append(0)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runTest(pooling, dropout, filter_info, loss, activation, final_activation, file_name='model.txt', model_name='model', save_model=False, epochs=5, batch_size=32):\n",
    "    #Dr. Patterson - you will need to update this line of code for it to work in your directory\n",
    "    recording_ids_dict, xy = import_data('/Users/jonathanlee/Desktop/Python/NICU/NICU_data')\n",
    "\n",
    "    matrices = {}\n",
    "    scores = {}\n",
    "    model_scores = {}\n",
    "    str_model =''\n",
    "\n",
    "    for i in recording_ids_dict:\n",
    "        print('Testing on ' + str(i))\n",
    "        train_ids= []\n",
    "        test_ids = []\n",
    "        \n",
    "        train_ids = recording_ids_dict.copy()\n",
    "        test_ids = {i:train_ids.pop(i)}\n",
    "    \n",
    "        x_rgb_train, x_depth_train, y_train = create_array(train_ids, xy)\n",
    "        x_rgb_test, x_depth_test, y_test = create_array(test_ids, xy)\n",
    "        \n",
    "        #Scaling the values to a value between 0 and 1\n",
    "        x_rgb_train = x_rgb_train.astype('float32')\n",
    "        x_rgb_test = x_rgb_test.astype('float32')\n",
    "        x_rgb_train /= 255\n",
    "        x_rgb_test /= 255\n",
    "        x_depth_train = x_depth_train.astype('float32')\n",
    "        x_depth_test = x_depth_test.astype('float32')\n",
    "        x_depth_train /= 255\n",
    "        x_depth_test /= 255\n",
    "        \n",
    "        print('shape rgb' + str(x_rgb_train.shape[1:]))\n",
    "        print('shape dept' + str(x_depth_train.shape[1:]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        depth_model,depth_str_model = create_cnn(x_depth_train,\n",
    "                                     filter_info=filter_info,\n",
    "                                     dropout=dropout,\n",
    "                                     pooling=pooling,\n",
    "                                     loss=loss,\n",
    "                                     final_activation=final_activation,\n",
    "                                     activation=activation)\n",
    "        \n",
    "        rgb_model,rgb_str_model = create_cnn(x_rgb_train,\n",
    "                                     filter_info=filter_info,\n",
    "                                     dropout=dropout,\n",
    "                                     pooling=pooling,\n",
    "                                     loss=loss,\n",
    "                                     final_activation=final_activation,\n",
    "                                     activation=activation)\n",
    "       \n",
    "        print('shape rgb ' + str(x_rgb_train.shape[1:]))\n",
    "        rgb_input = Input(shape=(x_rgb_train.shape[1:]))\n",
    "        encoded_rgb = TimeDistributed(rgb_model)(rgb_input)\n",
    "        \n",
    "        print('shape depth ' + str(x_depth_train.shape[1:]))\n",
    "        depth_input = Input(shape=(x_depth_train.shape[1:]))\n",
    "        encoded_depth = TimeDistributed(depth_model)(depth_input)\n",
    "        \n",
    "        #Fit the model\n",
    "        merged = keras.layers.concatenate([encoded_rgb, encoded_depth], axis=4)\n",
    "        conv1 = Conv3D(32, (3,3,3), activation=activation)(merged)\n",
    "        conv2 = Conv3D(64, (3,3,3), activation=activation)(conv1)\n",
    "        max2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "        flatten= Flatten()(max2)\n",
    "        dense1 = Dense(128, activation=activation)(flatten)\n",
    "        dense2 = Dense(64, activation=activation)(dense1)\n",
    "        output = Dense(1, activation='sigmoid')(dense2)\n",
    "        \n",
    "        model = Model(inputs=[rgb_input, depth_input], outputs=output)\n",
    "        \n",
    "        print(model.summary())\n",
    "        \n",
    "        adam = keras.optimizers.Adam(lr=0.0001,)\n",
    "        \n",
    "        model.compile(optimizer=adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['binary_accuracy'])\n",
    "    \n",
    "        model.fit([x_rgb_train, x_depth_train], [y_train],\n",
    "          epochs=10, batch_size=32)\n",
    "        \n",
    "    \n",
    "        #Create predictions and evaluate to find loss and accuaracy\n",
    "        model_score = model.evaluate(x =[x_rgb_test, x_depth_test], y=y_test)\n",
    "        predict = model.predict([x_rgb_test, x_depth_test])\n",
    "        print(predict)\n",
    "        print('Model was ' + str(model_score[1]) + '% accurate and exhibited an average loss of ' + str(model_score[0]) + '.')\n",
    "        \n",
    "        matrix,score = confusion_matrix(y_test, predict)\n",
    "        \n",
    "        matrices.update({i : matrix})\n",
    "        print(str(matrix) + '\\n')\n",
    "        scores.update({i: score})\n",
    "        print(str(score) + '\\n')\n",
    "        model_scores.update({i:model_score})\n",
    "   \n",
    "    with open(file_name, 'w') as f:\n",
    "        for key in matrices:\n",
    "            f.write(\"Baby %s\\n\" % key)\n",
    "            f.write(\"%s\\n\" % str_model)\n",
    "            f.write(\"%s\\n\" % matrices[key])\n",
    "            f.write(\"%s\\n\" % scores[key])\n",
    "            f.write(\"%s\\n\" % model_scores[key])\n",
    "        \n",
    "            \n",
    "    if save_model : \n",
    "        model.save(model)\n",
    "    #Add a final matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 2\n",
      "Num is 252 and num isn't 500\n",
      "Length of training set\n",
      "876\n",
      "Num is 25 and num isn't 163\n",
      "Length of training set\n",
      "257\n",
      "shape rgb(10, 96, 128, 3)\n",
      "shape dept(10, 96, 128, 3)\n",
      "Overview of Model Architecture: \n",
      "2D Convulution Layer with 32 filters the size of (3,3) and relu activation \n",
      "2D Convulution Layer with 32 filters the size of (3,3) and relu activation \n",
      "2D Pooling Max Pooling Layer with filter size (2,2)\n",
      "Droput Layer with with a rate of 0.250000 \n",
      "\n",
      "Overview of Model Architecture: \n",
      "2D Convulution Layer with 32 filters the size of (3,3) and relu activation \n",
      "2D Convulution Layer with 32 filters the size of (3,3) and relu activation \n",
      "2D Pooling Max Pooling Layer with filter size (2,2)\n",
      "Droput Layer with with a rate of 0.250000 \n",
      "\n",
      "shape rgb (10, 96, 128, 3)\n",
      "shape depth (10, 96, 128, 3)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_42 (InputLayer)           (None, 10, 96, 128,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_43 (InputLayer)           (None, 10, 96, 128,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_39 (TimeDistri (None, 10, 46, 62, 3 10144       input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_40 (TimeDistri (None, 10, 46, 62, 3 10144       input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 10, 46, 62, 6 0           time_distributed_39[0][0]        \n",
      "                                                                 time_distributed_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_31 (Conv3D)              (None, 8, 44, 60, 32 55328       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_32 (Conv3D)              (None, 6, 42, 58, 64 55360       conv3d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling3D) (None, 3, 21, 29, 64 0           conv3d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 116928)       0           max_pooling3d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 128)          14966912    flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 64)           8256        dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 1)            65          dense_41[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 15,106,209\n",
      "Trainable params: 15,106,209\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "876/876 [==============================] - 1188s 1s/step - loss: 0.5674 - binary_accuracy: 0.7009\n",
      "Epoch 2/10\n",
      "876/876 [==============================] - 1229s 1s/step - loss: 0.4340 - binary_accuracy: 0.7979\n",
      "Epoch 3/10\n",
      "876/876 [==============================] - 1214s 1s/step - loss: 0.3375 - binary_accuracy: 0.8470\n",
      "Epoch 4/10\n",
      "876/876 [==============================] - 1250s 1s/step - loss: 0.2348 - binary_accuracy: 0.9121\n",
      "Epoch 5/10\n",
      "876/876 [==============================] - 1223s 1s/step - loss: 0.1823 - binary_accuracy: 0.9361\n",
      "Epoch 6/10\n",
      "876/876 [==============================] - 3638s 4s/step - loss: 0.0959 - binary_accuracy: 0.9692\n",
      "Epoch 7/10\n",
      "876/876 [==============================] - 1386s 2s/step - loss: 0.1050 - binary_accuracy: 0.9600\n",
      "Epoch 8/10\n",
      "876/876 [==============================] - 1351s 2s/step - loss: 0.0679 - binary_accuracy: 0.9772\n",
      "Epoch 9/10\n",
      "876/876 [==============================] - 1350s 2s/step - loss: 0.0523 - binary_accuracy: 0.9829\n",
      "Epoch 10/10\n",
      "876/876 [==============================] - 1390s 2s/step - loss: 0.0828 - binary_accuracy: 0.9669\n",
      "257/257 [==============================] - 191s 743ms/step\n",
      "[[1.92502141e-03]\n",
      " [1.42359734e-03]\n",
      " [2.36362219e-03]\n",
      " [2.75126100e-03]\n",
      " [1.99401379e-03]\n",
      " [8.88794661e-04]\n",
      " [4.24057245e-04]\n",
      " [5.77569008e-04]\n",
      " [1.15567446e-03]\n",
      " [3.48383188e-03]\n",
      " [5.36900759e-03]\n",
      " [7.34436512e-03]\n",
      " [5.08129597e-03]\n",
      " [6.07383251e-03]\n",
      " [7.82471895e-03]\n",
      " [1.08342469e-02]\n",
      " [1.02172494e-02]\n",
      " [9.11957026e-03]\n",
      " [5.94067574e-03]\n",
      " [4.70641255e-03]\n",
      " [7.02467561e-03]\n",
      " [1.29853487e-02]\n",
      " [2.65241861e-02]\n",
      " [4.74382341e-02]\n",
      " [7.30166733e-02]\n",
      " [7.61748552e-02]\n",
      " [5.27118444e-02]\n",
      " [3.23114097e-02]\n",
      " [3.78862023e-02]\n",
      " [7.98057914e-02]\n",
      " [1.82454020e-01]\n",
      " [2.79392958e-01]\n",
      " [3.20911944e-01]\n",
      " [3.48127663e-01]\n",
      " [3.03197920e-01]\n",
      " [1.03288531e-01]\n",
      " [2.12345719e-02]\n",
      " [7.76085258e-03]\n",
      " [4.80946898e-03]\n",
      " [4.43413854e-03]\n",
      " [3.17993760e-03]\n",
      " [1.74447894e-03]\n",
      " [3.21146846e-03]\n",
      " [1.13177299e-02]\n",
      " [4.60725129e-02]\n",
      " [1.45551622e-01]\n",
      " [2.10472912e-01]\n",
      " [1.51725352e-01]\n",
      " [4.90840971e-02]\n",
      " [1.17802918e-02]\n",
      " [1.17406845e-02]\n",
      " [2.95341909e-02]\n",
      " [1.37473762e-01]\n",
      " [3.61429274e-01]\n",
      " [4.59900022e-01]\n",
      " [4.69773591e-01]\n",
      " [6.17368639e-01]\n",
      " [6.16753817e-01]\n",
      " [5.28177857e-01]\n",
      " [1.61751717e-01]\n",
      " [2.00750530e-02]\n",
      " [4.50184941e-03]\n",
      " [2.06241012e-03]\n",
      " [2.37876177e-03]\n",
      " [2.19962001e-03]\n",
      " [1.46129727e-03]\n",
      " [1.18520856e-03]\n",
      " [1.51547790e-03]\n",
      " [2.87553668e-03]\n",
      " [6.81853294e-03]\n",
      " [1.70148611e-02]\n",
      " [4.56208289e-02]\n",
      " [5.21278083e-02]\n",
      " [1.21180415e-02]\n",
      " [4.16821241e-03]\n",
      " [2.52994895e-03]\n",
      " [2.91398168e-03]\n",
      " [7.23731518e-03]\n",
      " [1.04488730e-02]\n",
      " [9.37512517e-03]\n",
      " [1.03530288e-02]\n",
      " [1.18173063e-02]\n",
      " [1.01380646e-02]\n",
      " [7.85285234e-03]\n",
      " [7.34466314e-03]\n",
      " [6.14827871e-03]\n",
      " [4.32062149e-03]\n",
      " [3.38521600e-03]\n",
      " [3.22118402e-03]\n",
      " [4.66585159e-03]\n",
      " [2.01466680e-03]\n",
      " [9.75430012e-04]\n",
      " [4.06891108e-04]\n",
      " [4.23073769e-04]\n",
      " [2.77021527e-03]\n",
      " [4.27279472e-02]\n",
      " [2.57703662e-01]\n",
      " [1.99017912e-01]\n",
      " [9.55377519e-02]\n",
      " [6.61579967e-02]\n",
      " [2.02199817e-02]\n",
      " [3.43918800e-03]\n",
      " [1.89939141e-03]\n",
      " [1.24332309e-03]\n",
      " [1.50135159e-03]\n",
      " [1.97193027e-03]\n",
      " [3.40232253e-03]\n",
      " [3.48663330e-03]\n",
      " [4.55847383e-03]\n",
      " [5.21239638e-03]\n",
      " [5.13464212e-03]\n",
      " [5.63311577e-03]\n",
      " [1.07782781e-02]\n",
      " [3.41578126e-02]\n",
      " [6.44095838e-02]\n",
      " [1.04355395e-01]\n",
      " [1.52635455e-01]\n",
      " [3.67245227e-01]\n",
      " [6.68644071e-01]\n",
      " [8.79565954e-01]\n",
      " [9.01087403e-01]\n",
      " [7.42333591e-01]\n",
      " [1.83657467e-01]\n",
      " [2.75166333e-02]\n",
      " [6.73437119e-03]\n",
      " [4.66614962e-03]\n",
      " [6.64326549e-03]\n",
      " [1.84442997e-02]\n",
      " [4.34038639e-02]\n",
      " [5.06837070e-02]\n",
      " [3.88940275e-02]\n",
      " [1.09504759e-02]\n",
      " [2.39899755e-03]\n",
      " [8.00758600e-04]\n",
      " [4.58419323e-04]\n",
      " [3.51548195e-04]\n",
      " [2.70187855e-04]\n",
      " [2.51293182e-04]\n",
      " [3.36945057e-04]\n",
      " [3.89993191e-04]\n",
      " [5.00231981e-04]\n",
      " [6.06089830e-04]\n",
      " [1.13171339e-03]\n",
      " [1.72635913e-03]\n",
      " [2.23109126e-03]\n",
      " [3.81982327e-03]\n",
      " [1.71597898e-02]\n",
      " [8.73321593e-02]\n",
      " [1.05924964e-01]\n",
      " [2.75190771e-02]\n",
      " [7.51248002e-03]\n",
      " [1.75994635e-03]\n",
      " [8.04305077e-04]\n",
      " [5.52326441e-04]\n",
      " [8.85099173e-04]\n",
      " [4.18159366e-03]\n",
      " [1.57802403e-02]\n",
      " [8.75246525e-02]\n",
      " [1.81045085e-01]\n",
      " [2.27881998e-01]\n",
      " [1.93121880e-01]\n",
      " [1.45980269e-01]\n",
      " [1.52378976e-01]\n",
      " [1.55382574e-01]\n",
      " [2.53084779e-01]\n",
      " [3.14420819e-01]\n",
      " [3.13272864e-01]\n",
      " [2.35285342e-01]\n",
      " [1.73415750e-01]\n",
      " [1.17028296e-01]\n",
      " [9.05789733e-02]\n",
      " [7.02035427e-02]\n",
      " [4.37745750e-02]\n",
      " [2.84006000e-02]\n",
      " [1.24646723e-02]\n",
      " [6.06769323e-03]\n",
      " [4.91243601e-03]\n",
      " [6.55695796e-03]\n",
      " [7.60599971e-03]\n",
      " [7.29033351e-03]\n",
      " [1.13241971e-02]\n",
      " [3.33261788e-02]\n",
      " [1.25202924e-01]\n",
      " [2.70534217e-01]\n",
      " [4.63072389e-01]\n",
      " [4.53958482e-01]\n",
      " [5.27146041e-01]\n",
      " [3.65201473e-01]\n",
      " [4.90840971e-02]\n",
      " [1.17802918e-02]\n",
      " [1.17406845e-02]\n",
      " [2.95341909e-02]\n",
      " [1.37473762e-01]\n",
      " [3.61429274e-01]\n",
      " [4.59900022e-01]\n",
      " [4.69773591e-01]\n",
      " [1.61751717e-01]\n",
      " [2.00750530e-02]\n",
      " [4.50184941e-03]\n",
      " [2.06241012e-03]\n",
      " [2.37876177e-03]\n",
      " [7.23731518e-03]\n",
      " [1.04488730e-02]\n",
      " [9.37512517e-03]\n",
      " [1.03530288e-02]\n",
      " [1.18173063e-02]\n",
      " [1.01380646e-02]\n",
      " [7.85285234e-03]\n",
      " [7.34466314e-03]\n",
      " [6.14827871e-03]\n",
      " [4.32062149e-03]\n",
      " [3.38521600e-03]\n",
      " [3.22118402e-03]\n",
      " [4.90840971e-02]\n",
      " [1.17802918e-02]\n",
      " [1.17406845e-02]\n",
      " [2.95341909e-02]\n",
      " [1.37473762e-01]\n",
      " [3.61429274e-01]\n",
      " [4.59900022e-01]\n",
      " [4.69773591e-01]\n",
      " [1.61751717e-01]\n",
      " [2.00750530e-02]\n",
      " [4.50184941e-03]\n",
      " [2.06241012e-03]\n",
      " [2.37876177e-03]\n",
      " [7.23731518e-03]\n",
      " [1.04488730e-02]\n",
      " [9.37512517e-03]\n",
      " [1.03530288e-02]\n",
      " [1.18173063e-02]\n",
      " [1.01380646e-02]\n",
      " [7.85285234e-03]\n",
      " [7.34466314e-03]\n",
      " [6.14827871e-03]\n",
      " [4.32062149e-03]\n",
      " [3.38521600e-03]\n",
      " [3.22118402e-03]\n",
      " [4.90840971e-02]\n",
      " [1.17802918e-02]\n",
      " [1.17406845e-02]\n",
      " [2.95341909e-02]\n",
      " [1.37473762e-01]\n",
      " [3.61429274e-01]\n",
      " [4.59900022e-01]\n",
      " [4.69773591e-01]\n",
      " [1.61751717e-01]\n",
      " [2.00750530e-02]\n",
      " [4.50184941e-03]\n",
      " [2.06241012e-03]\n",
      " [2.37876177e-03]\n",
      " [7.23731518e-03]\n",
      " [1.04488730e-02]\n",
      " [9.37512517e-03]\n",
      " [1.03530288e-02]\n",
      " [1.18173063e-02]\n",
      " [1.01380553e-02]]\n",
      "Model was 0.603112840466926% accurate and exhibited an average loss of 1.5590065351256137.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       E0    E1\n",
      "P0  153.0  86.0\n",
      "P1   10.0   8.0\n",
      "\n",
      "0.6264591439688716\n",
      "\n",
      "Testing on 3\n",
      "Num is 228 and num isn't 524\n",
      "Length of training set\n",
      "900\n",
      "Num is 49 and num isn't 139\n",
      "Length of training set\n",
      "233\n",
      "shape rgb(10, 96, 128, 3)\n",
      "shape dept(10, 96, 128, 3)\n",
      "Overview of Model Architecture: \n",
      "2D Convulution Layer with 32 filters the size of (3,3) and relu activation \n",
      "2D Convulution Layer with 32 filters the size of (3,3) and relu activation \n",
      "2D Pooling Max Pooling Layer with filter size (2,2)\n",
      "Droput Layer with with a rate of 0.250000 \n",
      "\n",
      "Overview of Model Architecture: \n",
      "2D Convulution Layer with 32 filters the size of (3,3) and relu activation \n",
      "2D Convulution Layer with 32 filters the size of (3,3) and relu activation \n",
      "2D Pooling Max Pooling Layer with filter size (2,2)\n",
      "Droput Layer with with a rate of 0.250000 \n",
      "\n",
      "shape rgb (10, 96, 128, 3)\n",
      "shape depth (10, 96, 128, 3)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_44 (InputLayer)           (None, 10, 96, 128,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_45 (InputLayer)           (None, 10, 96, 128,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_41 (TimeDistri (None, 10, 46, 62, 3 10144       input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_42 (TimeDistri (None, 10, 46, 62, 3 10144       input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 10, 46, 62, 6 0           time_distributed_41[0][0]        \n",
      "                                                                 time_distributed_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_33 (Conv3D)              (None, 8, 44, 60, 32 55328       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_34 (Conv3D)              (None, 6, 42, 58, 64 55360       conv3d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling3D) (None, 3, 21, 29, 64 0           conv3d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 116928)       0           max_pooling3d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 128)          14966912    flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 64)           8256        dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 1)            65          dense_44[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 15,106,209\n",
      "Trainable params: 15,106,209\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x134645ef0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jonathanlee/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1448, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-a982784d160d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         final_activation='sigmoid')\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-132-7ebb4973f6c6>\u001b[0m in \u001b[0;36mrunTest\u001b[0;34m(pooling, dropout, filter_info, loss, activation, final_activation, file_name, model_name, save_model, epochs, batch_size)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         model.fit([x_rgb_train, x_depth_train], [y_train],\n\u001b[0;32m---> 81\u001b[0;31m           epochs=10, batch_size=32)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 199\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels = [\"LeftArm\", \"RightArm\", \"LeftLeg\",\"RightLeg\"]\n",
    "names = [\"/Isaiah\", \"/Kaylee\", \"/Patterson\", \"/Ryan\"]\n",
    "\n",
    "#File name for the statistics to be save in. Must include .txt at the end\n",
    "file_name = 'test.txt'\n",
    "\n",
    "#Must have the h5py package installed or the model will not save. This should be the path of the location you would like\n",
    "#To save the model\n",
    "model_file_name = 'test'\n",
    "\n",
    "filter_info={0:[32,3]}\n",
    "dropout={0:0.25}\n",
    "pooling={0:2}\n",
    "\n",
    "\n",
    "runTest(file_name=file_name, \n",
    "        filter_info=filter_info, \n",
    "        dropout=dropout, \n",
    "        pooling=pooling, \n",
    "        loss='mean_squared_error', \n",
    "        activation='relu',\n",
    "        epochs=2, \n",
    "        batch_size=16,\n",
    "        final_activation='sigmoid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
