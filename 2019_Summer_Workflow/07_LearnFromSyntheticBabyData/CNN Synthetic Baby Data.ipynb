{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import from the Keras library\n",
    "from keras import models\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D,  MaxPooling2D\n",
    "from keras import optimizers \n",
    "from keras import utils\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#from secret import credentials\n",
    "\n",
    "#Other import statements \n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import cv2\n",
    "import pymysql\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The values by which to resize images\n",
    "nrows = 150\n",
    "ncols = 150 \n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect(): \n",
    "    db_host ='nicu-2019-03-05.c2lckhwrw1as.us-east-1.rds.amazonaws.com'\n",
    "    db_port = 3306\n",
    "    db_name = 'nicu'\n",
    "    db_username = 'jonlee'\n",
    "    db_password = 'nicu_jon'\n",
    "    \n",
    "    '''\n",
    "    db_host = credentials['db_host'];\n",
    "    db_port = credentials['db_port'];\n",
    "    db_name = credentials['db_name'];\n",
    "    db_username = credentials['db_username']\n",
    "    db_password = credentials['db_password']\n",
    "    '''\n",
    "    \n",
    "    conn = pymysql.connect(db_host, user=db_username, port=db_port, passwd=db_password, db=db_name)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_data(cache_path, conn=connect()): \n",
    "\n",
    "    curs = conn.cursor()\n",
    "    \n",
    "    recording_ids = {}\n",
    "    xy = {}    \n",
    "        \n",
    "    image_query = \"SELECT r.id, r.recording_id, r.isCSGM FROM nicu.Video_Raw AS r JOIN nicu.Video_Generated AS g ON r.id=g.raw_id  WHERE (r.recording_id>1) AND (g.RGB_Optical_Flow IS NOT NULL) LIMIT 2000\"\n",
    "    try:\n",
    "        curs.execute(image_query) #(list(recording_ids.keys())))\n",
    "        for row in curs.fetchall():\n",
    "            raw_id = row[0]\n",
    "            rec_id = row[1]\n",
    "            csgm = row[2]\n",
    "            if rec_id in recording_ids:\n",
    "                recording_ids.get(rec_id).append(raw_id)\n",
    "            else:\n",
    "                recording_ids.update({rec_id:[raw_id]})\n",
    "            xy.update({raw_id:[csgm]})\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving ID's\", e)\n",
    "        raise e\n",
    "        \n",
    "    for rec_id in recording_ids:\n",
    "        #cache_path = cache_path+\"recording_\"+(\"{:02d}\".format(rec_id))\n",
    "        cache_path = cache_path+'testing'\n",
    "        if not os.path.exists(cache_path):\n",
    "            os.mkdir(cache_path)\n",
    "        raw_id_list = recording_ids.get(rec_id)\n",
    "        for raw_id in raw_id_list:\n",
    "            current_input = cache_path+'/'+str(raw_id)+\".oflow.png\"\n",
    "            if not os.path.exists(current_input):\n",
    "                try:\n",
    "                    image_query = \"SELECT RGB_Optical_Flow from Video_Generated WHERE (raw_id=%s)\"\n",
    "                    curs.execute(image_query, (str(raw_id)))\n",
    "                    for row in curs.fetchall():\n",
    "                        db_img = row[0]\n",
    "                        if db_img is not None:\n",
    "                            img=cv2.imdecode(np.asarray(bytearray(db_img),dtype=np.uint8),cv2.IMREAD_UNCHANGED)\n",
    "                            cv2.imwrite(current_input,img)\n",
    "                except Exception as e:\n",
    "                        print(\"Error retrieving Optical Flow frame\",e)\n",
    "                        raise e\n",
    "            xy.get(raw_id).insert(0,cv2.imread(current_input))\n",
    "    curs.close()\n",
    "    \n",
    "    return recording_ids, xy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_array(raw_ids, xy):    \n",
    "    image_list=[]\n",
    "    csgm_list=[]\n",
    "    \n",
    "    random.shuffle(raw_ids)\n",
    "    \n",
    "    for i in raw_ids:\n",
    "        #if not xy.get(i)[0] == None:\n",
    "        image_list.append(xy.get(i)[0])\n",
    "        csgm_list.append(xy.get(i)[1])\n",
    "    x = np.array(image_list)\n",
    "    y = np.array(csgm_list)\n",
    "    return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(x_train):    \n",
    "    model = models.Sequential() \n",
    "\n",
    "    #The model will learn 32 filters in this layer\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu', input_shape=x_train.shape[1:])) # this applies 32 convolution filters of size 3x3 each\n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "\n",
    "    #Max Pooling takes a 2x2 grid and takes the highest value of the grid and resizes based on that max value\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #Softmax activation is the traditional form of activation for mutliclass classification\n",
    "    model.add(Dense(1, activation='softmax')) \n",
    "    \n",
    "    model.compile(loss='categorical_hinge', \n",
    "              optimizer=optimizers.SGD(lr=1e-4), #SGD = Stochastic Gradient Descent (Can be changed)\n",
    "              metrics=['acc']) \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(exp_values, predicted_values):\n",
    "    \"\"\"\n",
    "    This creates a confusion matrix with the predicted accuracy of the model.\n",
    "    The ouput is a pandas dataframe with the labels and columns of the different labels inputted. \n",
    "    \"\"\"\n",
    "    predicted_values = convert_predictions(predicted_values)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Creates a DataFrame of zeros\n",
    "    matrix = pd.DataFrame(np.zeros((2,2)) , ['P0','P1'], ['E0','E1'])\n",
    "    \n",
    "    #Caculates whether the score was right or wrong \n",
    "    for i in range(len(exp_values)):\n",
    "        if exp_values[i] == predicted_values[i]:\n",
    "            matrix.iloc[[predicted_values[i]],[predicted_values[i]]] += 1\n",
    "        elif exp_values[i][j] == 0 and predicted_values[i][j] == 1:\n",
    "            matrix.iloc[[predicted_values[i]],[expected_values[i]]] += 1\n",
    "   \n",
    "    #Calculate diagonal sum and the accuracy of the model\n",
    "    diagonal_sum = 0\n",
    "    for i in range(size):\n",
    "        diagonal_sum += matrix.iloc[i][i]\n",
    "    \n",
    "    score = diagonal_sum/len(exp_values)\n",
    "    \n",
    "  \n",
    "    return  matrix, score\n",
    "    \n",
    "    \n",
    "            \n",
    "def convert_predictions(predictions): \n",
    "    \"\"\"\n",
    "    Converts predictions outputted by a keras model into a list with 1 represented the predicted output and zero \n",
    "    in other classes. \n",
    "    \"\"\"\n",
    "    for p in predictions: \n",
    "        if p >= 0.5:\n",
    "            p = 1\n",
    "        else:\n",
    "            p = 0\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runTest(file_name, model_name, augmenting=False):\n",
    "    matrices = {}\n",
    "    scores = {}\n",
    "    model_scores = {}\n",
    "    \n",
    "    recording_ids_dict, xy = import_data('/Users/jonathanlee/Desktop/Python/NICU/NICU_data')\n",
    "    \n",
    "\n",
    "    for i in recording_ids_dict:\n",
    "        print('Testing on ' + str(i))\n",
    "        train_ids= []\n",
    "        test_ids = []\n",
    "        \n",
    "        for j in recording_ids_dict:\n",
    "            if j == i:\n",
    "                test_ids = recording_ids_dict[j]\n",
    "            else: \n",
    "                train_ids.extend(list(recording_ids_dict[j]))\n",
    "        \n",
    "        x_train, y_train = create_array(train_ids, xy)\n",
    "        x_test, y_test = create_array(test_ids, xy)\n",
    "        \n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "        \n",
    "        \n",
    "        model = create_model(x_train)\n",
    "        \n",
    "        #Fit the model\n",
    "        if not augmenting:\n",
    "            print('Not using data augmentation.')\n",
    "            model.fit(x_train, y_train, batch_size = 32, epochs = 5)\n",
    "        else:\n",
    "            imggen = ImageDataGenerator(rotation_range=0) #Rotates images slightly at random to account for differences\n",
    "        \n",
    "            imggen.fit(x_train)\n",
    "            \n",
    "            model.fit_generator(imggen.flow(x_train, y_train,bath),\n",
    "                        epochs=5,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "        #Create predictions and evaluate to find loss and accuaracy\n",
    "        predict = model.predict(x_test)\n",
    "        model_score = model.evaluate(x_test, y_test)\n",
    "        print('Model was ' + model_score[1] + '% accurate and exhibited an average loss of ' + model_score[0] + '.')\n",
    "        \n",
    "        matrix,score = confusion_matrix( y_test, predict, labels)\n",
    "        \n",
    "        matrices.update({i : matrix})\n",
    "        print(matrices + '/n')\n",
    "        scores.update({i: score})\n",
    "        print(scores + '/n')\n",
    "        model_scores.update({i:model_score})\n",
    "           \n",
    "    with open('LargeHingeResults.txt', 'w') as f:\n",
    "        for key in matrices:\n",
    "            f.write(\"%s\\n\" % key)\n",
    "            f.write(\"%s\\n\" % matrices[key])\n",
    "            f.write(\"%s\\n\" % scores[key])\n",
    "            f.write(\"%s\\n\" % model_scores[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving ID's (0, '')\n"
     ]
    },
    {
     "ename": "InterfaceError",
     "evalue": "(0, '')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d18233c183ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrunTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_file_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maugmenting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0a562757b7fc>\u001b[0m in \u001b[0;36mrunTest\u001b[0;34m(file_name, model_name, augmenting)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mrecording_ids_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/jonathanlee/Desktop/Python/NICU/NICU_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9ec84830cede>\u001b[0m in \u001b[0;36mimport_data\u001b[0;34m(cache_path, conn)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error retrieving ID's\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrec_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecording_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9ec84830cede>\u001b[0m in \u001b[0;36mimport_data\u001b[0;34m(cache_path, conn)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimage_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SELECT r.id, r.recording_id, r.isCSGM FROM nicu.Video_Raw AS r JOIN nicu.Video_Generated AS g ON r.id=g.raw_id  WHERE (r.recording_id>1) AND (g.RGB_Optical_Flow IS NOT NULL) LIMIT 2000\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_query\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(list(recording_ids.keys())))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mraw_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymysql/cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymysql/cursors.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_executed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogateescape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affected_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_query_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affected_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m_execute_command\u001b[0;34m(self, command, sql)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(0, '')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;31m# If the last query was unbuffered, make sure it finishes before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInterfaceError\u001b[0m: (0, '')"
     ]
    }
   ],
   "source": [
    "labels = [\"LeftArm\", \"RightArm\", \"LeftLeg\",\"RightLeg\"]\n",
    "names = [\"/Isaiah\", \"/Kaylee\", \"/Patterson\", \"/Ryan\"]\n",
    "\n",
    "file_name = 'test'\n",
    "model_file_name = 'test'\n",
    "runTest(file_name,model_file_name,augmenting=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
