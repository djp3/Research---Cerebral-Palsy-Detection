{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import from the Keras library\n",
    "from keras import models\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D,  MaxPooling2D\n",
    "from keras import optimizers \n",
    "from keras import utils\n",
    "from keras.models import load_model\n",
    "from secret import credentials\n",
    "\n",
    "#Other import statements \n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import cv2\n",
    "import pymysql\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The values by which to resize images\n",
    "nrows = 150\n",
    "ncols = 150 \n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect(): \n",
    "    db_host ='nicu-2019-03-05.c2lckhwrw1as.us-east-1.rds.amazonaws.com'\n",
    "    db_port = 3306\n",
    "    db_name = 'nicu'\n",
    "    db_username = 'jonlee'\n",
    "    db_password = 'nicu_jon'\n",
    "    \n",
    "    '''\n",
    "    db_host = credentials['db_host'];\n",
    "    db_port = credentials['db_port'];\n",
    "    db_name = credentials['db_name'];\n",
    "    db_username = credentials['db_username']\n",
    "    db_password = credentials['db_password']\n",
    "    '''\n",
    "    \n",
    "    conn = pymysql.connect(db_host, user=db_username, port=db_port, passwd=db_password, db=db_name)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(cache_path, conn=connect()): \n",
    "\n",
    "    curs = conn.cursor()\n",
    "    \n",
    "    recording_ids = {}\n",
    "    xy = {}    \n",
    "        \n",
    "    image_query = \"SELECT r.id, r.recording_id, r.isCSGM FROM nicu.Video_Raw AS r JOIN nicu.Video_Generated AS g ON r.id=g.raw_id  WHERE (r.recording_id>1) AND (g.RGB_Optical_Flow IS NOT NULL) LIMIT 10\"\n",
    "    try:\n",
    "        curs.execute(image_query) #(list(recording_ids.keys())))\n",
    "        for row in curs.fetchall():\n",
    "            raw_id = row[0]\n",
    "            rec_id = row[1]\n",
    "            csgm = row[2]\n",
    "            if rec_id in recording_ids:\n",
    "                recording_ids.get(rec_id).append(raw_id)\n",
    "            else:\n",
    "                recording_ids.update({rec_id:[raw_id]})\n",
    "            xy.update({raw_id:[csgm]})\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving ID's\", e)\n",
    "        raise e\n",
    "        \n",
    "    for rec_id in recording_ids:\n",
    "        #cache_path = cache_path+\"recording_\"+(\"{:02d}\".format(rec_id))\n",
    "        cache_path = cache_path+'testing'\n",
    "        if not os.path.exists(cache_path):\n",
    "            os.mkdir(cache_path)\n",
    "        raw_id_list = recording_ids.get(rec_id)\n",
    "        for raw_id in raw_id_list:\n",
    "            current_input = cache_path+'/'+str(raw_id)+\".oflow.png\"\n",
    "            if not os.path.exists(current_input):\n",
    "                try:\n",
    "                    image_query = \"SELECT RGB_Optical_Flow from Video_Generated WHERE (raw_id=%s)\"\n",
    "                    curs.execute(image_query, (str(raw_id)))\n",
    "                    for row in curs.fetchall():\n",
    "                        db_img = row[0]\n",
    "                        if db_img is not None:\n",
    "                            img=cv2.imdecode(np.asarray(bytearray(db_img),dtype=np.uint8),cv2.IMREAD_UNCHANGED)\n",
    "                            cv2.imwrite(current_input,img)\n",
    "                except Exception as e:\n",
    "                        print(\"Error retrieving Optical Flow frame\",e)\n",
    "                        raise e\n",
    "            xy.get(raw_id).insert(0,cv2.imread(current_input))\n",
    "    curs.close()\n",
    "    \n",
    "    return recording_ids, xy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_array(raw_ids, xy):    \n",
    "    image_list=[]\n",
    "    csgm_list=[]\n",
    "    \n",
    "    random.shuffle(raw_ids)\n",
    "    \n",
    "    for i in raw_ids:\n",
    "        if xy.get(i)[0]!=None:\n",
    "            image_list.append(xy.get(i)[0])\n",
    "            csgm_list.append(xy.get(i)[1])\n",
    "    x = np.array(image_list)\n",
    "    y = np.array(csgm_list)\n",
    "    return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():    \n",
    "    model = models.Sequential() \n",
    "\n",
    "    #The model will learn 32 filters in this layer\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu', input_shape=(150,150,3))) # this applies 32 convolution filters of size 3x3 each\n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "\n",
    "    #Max Pooling takes a 2x2 grid and takes the highest value of the grid and resizes based on that max value\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #Softmax activation is the traditional form of activation for mutliclass classification\n",
    "    model.add(Dense(1, activation='softmax')) \n",
    "    \n",
    "    model.compile(loss='categorical_hinge', \n",
    "              optimizer=optimizers.SGD(lr=1e-4), #SGD = Stochastic Gradient Descent (Can be changed)\n",
    "              metrics=['acc']) \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(size, exp_values, predicted_values, labels):\n",
    "    \"\"\"\n",
    "    This creates a confusion matrix with the predicted accuracy of the model.\n",
    "    The ouput is a pandas dataframe with the labels and columns of the different labels inputted. \n",
    "    \"\"\"\n",
    "    predicted_values = convert_predictions(predicted_values)\n",
    "    \n",
    "    #Creates a DataFrame of zeros\n",
    "    matrix = pd.DataFrame(np.zeros((size,size)) , labels, labels)\n",
    "    \n",
    "    #Caculates whether the score was right or wrong \n",
    "    for i in range(len(exp_values)):\n",
    "        for j in range(size):\n",
    "            if exp_values[i][j] == predicted_values[i][j] and predicted_values[i][j] == 1:\n",
    "                matrix.iloc[[find_one(predicted_values[i])],[find_one(exp_values[i])]] += 1\n",
    "            elif exp_values[i][j] == 0 and predicted_values[i][j] == 1:\n",
    "                matrix.iloc[[find_one(predicted_values[i])],[find_one(exp_values[i])]] += 1\n",
    "   \n",
    "    #Calculate diagonal sum and the accuracy of the model\n",
    "    diagonal_sum = 0\n",
    "    for i in range(size):\n",
    "        diagonal_sum += matrix.iloc[i][i]\n",
    "    \n",
    "    score = diagonal_sum/len(exp_values)\n",
    "    \n",
    "  \n",
    "    return  matrix, score\n",
    "    \n",
    "    \n",
    "def find_one(l):\n",
    "    \"\"\"\n",
    "    Finds the first occurence of one in a list and returns it.\n",
    "    \"\"\"\n",
    "    for i in range(len(l)): \n",
    "        if l[i] == 1: return i\n",
    "    return 0\n",
    "            \n",
    "def convert_predictions(predictions): \n",
    "    \"\"\"\n",
    "    Converts predictions outputted by a keras model into a list with 1 represented the predicted output and zero \n",
    "    in other classes. \n",
    "    \"\"\"\n",
    "    for p in predictions: \n",
    "        max_val = max(p)\n",
    "        for n in range(len(p)): \n",
    "            if p[n] == max_val:\n",
    "                p[n] = 1\n",
    "            else:\n",
    "                p[n] = 0\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runTest():\n",
    "    matrices = {}\n",
    "    scores = {}\n",
    "    model_scores = {}\n",
    "    \n",
    "    recording_ids_dict, xy = import_data('NICU_data/')\n",
    "    \n",
    "    for i in recording_ids_dict:\n",
    "        train_ids= []\n",
    "        test_ids = []\n",
    "        \n",
    "        for j in recording_ids_dict:\n",
    "            if j == i:\n",
    "                test_ids = recording_ids_dict[j]\n",
    "            else: \n",
    "                train_ids = train_ids.append(recording_ids_dict[j])\n",
    "        \n",
    "        x_train, y_train = create_array(train_ids, xy)\n",
    "        x_test, y_test = create_array(test_ids, xy)\n",
    "        \n",
    "        model = create_model()\n",
    "        \n",
    "        #Fit the model\n",
    "        model.fit(x_train, y_train, batch_size = 32, epochs = 5)\n",
    "        \n",
    "        #Create predictions and evaluate to find loss and accuaracy\n",
    "        predict = model.predict(x_test)\n",
    "        model_score = model.evaluate(x_test, y_test)\n",
    "        \n",
    "        matrix,score = confusion_matrix(len(y_test[0]), y_test, predict, labels)\n",
    "        \n",
    "        matrices.update({i : matrix})\n",
    "        print(matrices)\n",
    "        scores.update({i: score})\n",
    "        print(scores)\n",
    "        model_scores.update({i:model_score})\n",
    "        \n",
    "    return matrices, scores, model_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Kaylee', '/Patterson', '/Ryan'] are the training names\n",
      "/Isaiah is being tested on.\n",
      "WARNING:tensorflow:From /Users/jonathanlee/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/jonathanlee/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/jonathanlee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/jonathanlee/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/5\n",
      "2039/2039 [==============================] - 209s 102ms/step - loss: 0.9849 - acc: 0.4836\n",
      "Epoch 2/5\n",
      "2039/2039 [==============================] - 745s 365ms/step - loss: 0.4436 - acc: 0.7989\n",
      "Epoch 3/5\n",
      "2039/2039 [==============================] - 1188s 583ms/step - loss: 0.2830 - acc: 0.8872\n",
      "Epoch 4/5\n",
      "1504/2039 [=====================>........] - ETA: 49s - loss: 0.2363 - acc: 0.9122"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6023b27893bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"LeftArm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RightArm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LeftLeg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"RightLeg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"/Isaiah\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/Kaylee\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/Patterson\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/Ryan\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmatrices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LargeHingeResults.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0280e9140a61>\u001b[0m in \u001b[0;36mrunTest\u001b[0;34m(names, labels)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#Create predictions and evaluate to find loss and accuaracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels = [\"LeftArm\", \"RightArm\", \"LeftLeg\",\"RightLeg\"]\n",
    "names = [\"/Isaiah\", \"/Kaylee\", \"/Patterson\", \"/Ryan\"]\n",
    "matrices, scores, model_scores = runTest(names,labels)\n",
    "\n",
    "with open('LargeHingeResults.txt', 'w') as f:\n",
    "    for key in matrices:\n",
    "        f.write(\"%s\\n\" % key)\n",
    "        f.write(\"%s\\n\" % matrices[key])\n",
    "        f.write(\"%s\\n\" % scores[key])\n",
    "        f.write(\"%s\\n\" % model_scores[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
